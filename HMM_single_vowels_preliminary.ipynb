{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognize Phones from Speech Sentences using Hidden Markov Model\n",
    "## Preliminary Testing on a SINGLE vowel\n",
    "\n",
    "For this project, a hidden markov model (HMM) is applied to create phone models for three different vowels (/a/, /u/, /i/). Then all three phone models are used to infer the state of a given speech sentence. The objective is to recognize the three phones from any given sentence with their corresponding time indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as collections\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hmmlearn_YG import hmm\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models\n",
    "\n",
    "[HMMs](https://en.wikipedia.org/wiki/Hidden_Markov_model) are a class of probabilistic graphical models that can predict the sequence of states, given a sequence of observations that are dependent on those states, and when the states themselves are unobservable. HMMs have seen widespread success in a variety of applications, from Speech processing and Robotics to DNA Sequencing. An HMM operates according to a set of assumptions, which are :  \n",
    "1. **Markov Assumption**  \n",
    "Current state is dependent on only the previous state.  \n",
    "2. **Stationarity Assumption**  \n",
    "Transition probabilities are independent of time of transition.  \n",
    "3. **Independence Assumption**  \n",
    "Each observation depends solely on the current underlying state (which in turn depends on the previous one), and is independent of other observations.  \n",
    "\n",
    "An HMM is a **Generative model**, in that it attempts to find the probability of a set of observations being produced or *generated* by a class.  The parameters that we pass to the HMM class, defined below, are:  \n",
    "$O$ = a set of observations  \n",
    "$S$ = a set of states  \n",
    "$A$ = transition probabilities, represented as a matrix  \n",
    "$B$ = emission probabilities, represented as a matrix  \n",
    "$\\pi$ = initial state probabilties  \n",
    "$Y$ = sequence observed  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Vowel Data for Training the HMM\n",
    "Load one normal vowels (/a/ normal, /u/ normal, /i/ normal) but only using voice channels, the normal vowels are used for fitting the Hidden Markov Model, generate all hidden state distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Subject and Vowel\n",
    "subject = \"R031\"\n",
    "vowel = \"a_normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([-0.00021115, -0.0001924 , -0.00014865, ...,  0.0007826 ,\n",
      "        0.00074823,  0.00080448])\n",
      "  20000]\n",
      " [array([0.00016859, 0.00020609, 0.00022484, ..., 0.00101547, 0.00104672,\n",
      "       0.00105922])\n",
      "  20000]\n",
      " [array([0.00025301, 0.00021551, 0.00020926, ..., 0.00032176, 0.00023739,\n",
      "       0.00013426])\n",
      "  20000]\n",
      " [array([-0.00054108, -0.00054733, -0.00058483, ..., -0.0013942 ,\n",
      "       -0.00145358, -0.00140983])\n",
      "  20000]\n",
      " [array([-6.42280793e-05, -4.86030476e-05,  8.26469623e-05, ...,\n",
      "       -1.54235307e-03, -2.85485305e-03, -4.32360312e-03])\n",
      "  20000]\n",
      " [array([-0.00012026, -0.00017964, -0.00013589, ..., -0.00894526,\n",
      "       -0.01089214, -0.01152964])\n",
      "  20000]\n",
      " [array([-1.51470012e-04, -1.20220124e-04, -2.01470044e-04, ...,\n",
      "       -8.89700605e-05, -9.83450445e-05, -6.08449918e-05])\n",
      "  20000]\n",
      " [array([-1.36763265e-04, -6.17632177e-05, -1.48882391e-05, ...,\n",
      "       -1.93013228e-04, -1.55513233e-04, -1.33638270e-04])\n",
      "  20000]\n",
      " [array([-0.00024809, -0.00017934, -0.00020746, ..., -0.00110121,\n",
      "       -0.00112934, -0.00114184])\n",
      "  20000]\n",
      " [array([-0.00015349, -0.00010349, -0.00013474, ...,  0.00238401,\n",
      "        0.00234338,  0.00231526])\n",
      "  20000]\n",
      " [array([-3.04934394e-04, -2.95559410e-04, -2.61184410e-04, ...,\n",
      "       -1.58059411e-04, -1.17434422e-04, -5.49344113e-05])\n",
      "  20000]\n",
      " [array([-0.00074492, -0.00071992, -0.00076055, ..., -0.00079492,\n",
      "       -0.00066055, -0.00073867])\n",
      "  20000]\n",
      " [array([-0.00053978, -0.00048665, -0.00037728, ...,  0.00066335,\n",
      "        0.0006321 ,  0.0005571 ])\n",
      "  20000]\n",
      " [array([-0.00014967, -0.00013717, -0.00018717, ..., -0.00160592,\n",
      "       -0.00281842, -0.00392467])\n",
      "  20000]\n",
      " [array([-1.50482228e-04, -8.48571653e-05, -1.12982234e-04, ...,\n",
      "        6.46201777e-03,  6.37764274e-03,  6.42139302e-03])\n",
      "  20000]\n",
      " [array([-0.0001185 , -0.000156  , -0.00013725, ..., -0.0011935 ,\n",
      "       -0.00115287, -0.00127475])\n",
      "  20000]\n",
      " [array([-0.00017782, -0.00020594, -0.00018407, ..., -0.01147782,\n",
      "       -0.01174344, -0.01195594])\n",
      "  20000]\n",
      " [array([0.00021872, 0.00028747, 0.00015934, ..., 0.00104684, 0.00106559,\n",
      "       0.00110622])\n",
      "  20000]\n",
      " [array([-0.00033611, -0.00027673, -0.00035173, ..., -0.00892673,\n",
      "       -0.00882048, -0.00873923])\n",
      "  20000]\n",
      " [array([0.00011716, 0.00015778, 0.00016091, ..., 0.00710153, 0.00733278,\n",
      "       0.00744528])\n",
      "  20000]\n",
      " [array([1.28000684e-04, 1.37375726e-04, 9.67507367e-05, ...,\n",
      "       1.03000843e-04, 1.71750726e-04, 1.34250789e-04])\n",
      "  20000]\n",
      " [array([-0.00026697, -0.0002826 , -0.0003576 , ...,  0.00087678,\n",
      "        0.00092678,  0.00089553])\n",
      "  20000]\n",
      " [array([-0.00037496, -0.00042184, -0.00045309, ...,  0.00085316,\n",
      "        0.00081566,  0.00083441])\n",
      "  20000]\n",
      " [array([-7.31318723e-05, -1.45006750e-04, -1.70006824e-04, ...,\n",
      "        1.20206182e-02,  1.15643684e-02,  1.06987436e-02])\n",
      "  20000]\n",
      " [array([-0.00012256, -0.00014443, -0.00013193, ...,  0.00855244,\n",
      "        0.00805557,  0.00773369])\n",
      "  20000]\n",
      " [array([-0.00027947, -0.00031072, -0.00029509, ...,  0.01201428,\n",
      "        0.01166116,  0.01080491])\n",
      "  20000]\n",
      " [array([-0.00019661, -0.00025911, -0.00021536, ..., -0.00263723,\n",
      "       -0.00376848, -0.00510598])\n",
      "  20000]\n",
      " [array([-0.00037228, -0.00032853, -0.00025665, ...,  0.0003996 ,\n",
      "        0.00040585,  0.00043397])\n",
      "  20000]\n",
      " [array([-0.00023715, -0.00021527, -0.00024652, ...,  0.00352848,\n",
      "        0.00372535,  0.0039191 ])\n",
      "  20000]\n",
      " [array([-0.0002026 , -0.00023072, -0.00023072, ...,  0.00018803,\n",
      "        0.0002099 ,  0.0001599 ])\n",
      "  20000]\n",
      " [array([-0.00022512, -0.000197  , -0.00015637, ...,  0.0001905 ,\n",
      "        0.00019988,  0.00015613])\n",
      "  20000]\n",
      " [array([-1.73015869e-04, -2.26140837e-04, -8.86408379e-05, ...,\n",
      "        3.05109075e-04,  2.73859245e-04,  3.14484234e-04])\n",
      "  20000]\n",
      " [array([-7.11995526e-05, -1.14949537e-04, -1.18074531e-04, ...,\n",
      "       -1.43074547e-04, -9.93244466e-05, -1.39949552e-04])\n",
      "  20000]\n",
      " [array([-1.29434280e-04, -9.19342274e-05, -1.82559306e-04, ...,\n",
      "       -3.04193434e-03, -3.14193428e-03, -3.26693431e-03])\n",
      "  20000]\n",
      " [array([-0.00012626, -0.00020751, -0.00025438, ..., -0.00030751,\n",
      "       -0.00022938, -0.00022001])\n",
      "  20000]\n",
      " [array([-0.00020097, -0.00014472, -0.00019784, ..., -0.00026659,\n",
      "       -0.00019784, -0.00019159])\n",
      "  20000]\n",
      " [array([ 5.80963097e-05,  3.93463415e-05,  5.49713150e-05, ...,\n",
      "       -1.01200291e-02, -8.92002834e-03, -7.64815370e-03])\n",
      "  20000]\n",
      " [array([-0.00012295, -0.0001292 , -0.00011358, ..., -0.0003667 ,\n",
      "       -0.00046358, -0.00044795])\n",
      "  20000]\n",
      " [array([-2.85602757e-04, -2.60602799e-04, -2.54352693e-04, ...,\n",
      "       -4.35271068e-06,  2.37722415e-05,  1.12722628e-05])\n",
      "  20000]\n",
      " [array([-0.00018209, -0.00017896, -0.00023209, ...,  0.00083354,\n",
      "        0.00084604,  0.00088041])\n",
      "  20000]\n",
      " [array([-0.00010901, -0.00010276, -0.00011526, ..., -0.00061526,\n",
      "       -0.00053088, -0.00050276])\n",
      "  20000]\n",
      " [array([ 2.64029950e-07, -8.41109431e-05, -6.22359803e-05, ...,\n",
      "       -3.09110968e-04, -3.24736000e-04, -3.80985963e-04])\n",
      "  20000]\n",
      " [array([-8.07247707e-05, -8.38498236e-05, -7.75997760e-05, ...,\n",
      "       -3.15099780e-04, -3.24474764e-04, -3.61974759e-04])\n",
      "  20000]\n",
      " [array([-0.00025545, -0.00028045, -0.00023358, ..., -0.00063358,\n",
      "       -0.0006117 , -0.00059295])\n",
      "  20000]\n",
      " [array([-2.10954575e-04, -1.14079623e-04, -9.84545914e-05, ...,\n",
      "        5.35920553e-04,  4.64045384e-04,  3.95295501e-04])\n",
      "  20000]\n",
      " [array([-0.00027318, -0.00023256, -0.00030443, ..., -0.00042943,\n",
      "       -0.00039193, -0.00037318])\n",
      "  20000]\n",
      " [array([-2.65048118e-04, -2.49423028e-04, -1.11923087e-04, ...,\n",
      "       -7.75480294e-05, -2.18173023e-04, -2.55673076e-04])\n",
      "  20000]\n",
      " [array([-2.35307554e-04, -1.88432517e-04, -2.29057507e-04, ...,\n",
      "       -1.25932565e-04, -8.53075180e-05, -1.38432486e-04])\n",
      "  20000]\n",
      " [array([-2.25204625e-04, -1.56454567e-04, -1.06454594e-04, ...,\n",
      "       -1.12704583e-04, -8.45796312e-05, -3.32959462e-06])\n",
      "  20000]\n",
      " [array([-0.00036108, -0.00028608, -0.00026108, ..., -0.00889546,\n",
      "       -0.00608608, -0.00292671])\n",
      "  20000]\n",
      " [array([-0.00022867, -0.00029117, -0.00027242, ...,  0.00094008,\n",
      "        0.00454633,  0.0083307 ])\n",
      "  20000]\n",
      " [array([-0.00030486, -0.00030799, -0.00039861, ..., -0.01137986,\n",
      "       -0.01212674, -0.01313299])\n",
      "  20000]\n",
      " [array([-0.00017855, -0.0002223 , -0.00018792, ..., -0.0034098 ,\n",
      "       -0.00323792, -0.0024223 ])\n",
      "  20000]\n",
      " [array([-3.10976116e-04, -3.32851196e-04, -3.32851138e-04, ...,\n",
      "       -1.60976197e-04, -1.60976197e-04, -9.53511335e-05])\n",
      "  20000]\n",
      " [array([-0.00017834, -0.00011896, -0.00016271, ...,  0.00021854,\n",
      "        0.00028416,  0.00024979])\n",
      "  20000]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.00021115 -0.0001924  -0.00014865 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.00016859 0.00020609 0.00022484 ... 0.001015...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.00025301 0.00021551 0.00020926 ... 0.000321...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.00054108 -0.00054733 -0.00058483 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-6.42280793e-05 -4.86030476e-05  8.26469623e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.00012026 -0.00017964 -0.00013589 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[-1.51470012e-04 -1.20220124e-04 -2.01470044e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[-1.36763265e-04 -6.17632177e-05 -1.48882391e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.00024809 -0.00017934 -0.00020746 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-0.00015349 -0.00010349 -0.00013474 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-3.04934394e-04 -2.95559410e-04 -2.61184410e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-0.00074492 -0.00071992 -0.00076055 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-0.00053978 -0.00048665 -0.00037728 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-0.00014967 -0.00013717 -0.00018717 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-1.50482228e-04 -8.48571653e-05 -1.12982234e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-0.0001185  -0.000156   -0.00013725 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[-0.00017782 -0.00020594 -0.00018407 ... -0.01...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[0.00021872 0.00028747 0.00015934 ... 0.001046...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[-0.00033611 -0.00027673 -0.00035173 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[0.00011716 0.00015778 0.00016091 ... 0.007101...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1.28000684e-04 1.37375726e-04 9.67507367e-05 ...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[-0.00026697 -0.0002826  -0.0003576  ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[-0.00037496 -0.00042184 -0.00045309 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[-7.31318723e-05 -1.45006750e-04 -1.70006824e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[-0.00012256 -0.00014443 -0.00013193 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[-0.00027947 -0.00031072 -0.00029509 ...  0.01...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[-0.00019661 -0.00025911 -0.00021536 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[-0.00037228 -0.00032853 -0.00025665 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[-0.00023715 -0.00021527 -0.00024652 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[-0.0002026  -0.00023072 -0.00023072 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[-0.00022512 -0.000197   -0.00015637 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[-1.73015869e-04 -2.26140837e-04 -8.86408379e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[-7.11995526e-05 -1.14949537e-04 -1.18074531e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[-1.29434280e-04 -9.19342274e-05 -1.82559306e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[-0.00012626 -0.00020751 -0.00025438 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[-0.00020097 -0.00014472 -0.00019784 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[ 5.80963097e-05  3.93463415e-05  5.49713150e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[-0.00012295 -0.0001292  -0.00011358 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[-2.85602757e-04 -2.60602799e-04 -2.54352693e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[-0.00018209 -0.00017896 -0.00023209 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[-0.00010901 -0.00010276 -0.00011526 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[ 2.64029950e-07 -8.41109431e-05 -6.22359803e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[-8.07247707e-05 -8.38498236e-05 -7.75997760e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[-0.00025545 -0.00028045 -0.00023358 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[-2.10954575e-04 -1.14079623e-04 -9.84545914e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[-0.00027318 -0.00023256 -0.00030443 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[-2.65048118e-04 -2.49423028e-04 -1.11923087e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[-2.35307554e-04 -1.88432517e-04 -2.29057507e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[-2.25204625e-04 -1.56454567e-04 -1.06454594e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[-0.00036108 -0.00028608 -0.00026108 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[-0.00022867 -0.00029117 -0.00027242 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[-0.00030486 -0.00030799 -0.00039861 ... -0.01...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[-0.00017855 -0.0002223  -0.00018792 ... -0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[-3.10976116e-04 -3.32851196e-04 -3.32851138e-...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[-0.00017834 -0.00011896 -0.00016271 ...  0.00...</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Signal   Rate\n",
       "0   [-0.00021115 -0.0001924  -0.00014865 ...  0.00...  20000\n",
       "1   [0.00016859 0.00020609 0.00022484 ... 0.001015...  20000\n",
       "2   [0.00025301 0.00021551 0.00020926 ... 0.000321...  20000\n",
       "3   [-0.00054108 -0.00054733 -0.00058483 ... -0.00...  20000\n",
       "4   [-6.42280793e-05 -4.86030476e-05  8.26469623e-...  20000\n",
       "5   [-0.00012026 -0.00017964 -0.00013589 ... -0.00...  20000\n",
       "6   [-1.51470012e-04 -1.20220124e-04 -2.01470044e-...  20000\n",
       "7   [-1.36763265e-04 -6.17632177e-05 -1.48882391e-...  20000\n",
       "8   [-0.00024809 -0.00017934 -0.00020746 ... -0.00...  20000\n",
       "9   [-0.00015349 -0.00010349 -0.00013474 ...  0.00...  20000\n",
       "10  [-3.04934394e-04 -2.95559410e-04 -2.61184410e-...  20000\n",
       "11  [-0.00074492 -0.00071992 -0.00076055 ... -0.00...  20000\n",
       "12  [-0.00053978 -0.00048665 -0.00037728 ...  0.00...  20000\n",
       "13  [-0.00014967 -0.00013717 -0.00018717 ... -0.00...  20000\n",
       "14  [-1.50482228e-04 -8.48571653e-05 -1.12982234e-...  20000\n",
       "15  [-0.0001185  -0.000156   -0.00013725 ... -0.00...  20000\n",
       "16  [-0.00017782 -0.00020594 -0.00018407 ... -0.01...  20000\n",
       "17  [0.00021872 0.00028747 0.00015934 ... 0.001046...  20000\n",
       "18  [-0.00033611 -0.00027673 -0.00035173 ... -0.00...  20000\n",
       "19  [0.00011716 0.00015778 0.00016091 ... 0.007101...  20000\n",
       "20  [1.28000684e-04 1.37375726e-04 9.67507367e-05 ...  20000\n",
       "21  [-0.00026697 -0.0002826  -0.0003576  ...  0.00...  20000\n",
       "22  [-0.00037496 -0.00042184 -0.00045309 ...  0.00...  20000\n",
       "23  [-7.31318723e-05 -1.45006750e-04 -1.70006824e-...  20000\n",
       "24  [-0.00012256 -0.00014443 -0.00013193 ...  0.00...  20000\n",
       "25  [-0.00027947 -0.00031072 -0.00029509 ...  0.01...  20000\n",
       "26  [-0.00019661 -0.00025911 -0.00021536 ... -0.00...  20000\n",
       "27  [-0.00037228 -0.00032853 -0.00025665 ...  0.00...  20000\n",
       "28  [-0.00023715 -0.00021527 -0.00024652 ...  0.00...  20000\n",
       "29  [-0.0002026  -0.00023072 -0.00023072 ...  0.00...  20000\n",
       "30  [-0.00022512 -0.000197   -0.00015637 ...  0.00...  20000\n",
       "31  [-1.73015869e-04 -2.26140837e-04 -8.86408379e-...  20000\n",
       "32  [-7.11995526e-05 -1.14949537e-04 -1.18074531e-...  20000\n",
       "33  [-1.29434280e-04 -9.19342274e-05 -1.82559306e-...  20000\n",
       "34  [-0.00012626 -0.00020751 -0.00025438 ... -0.00...  20000\n",
       "35  [-0.00020097 -0.00014472 -0.00019784 ... -0.00...  20000\n",
       "36  [ 5.80963097e-05  3.93463415e-05  5.49713150e-...  20000\n",
       "37  [-0.00012295 -0.0001292  -0.00011358 ... -0.00...  20000\n",
       "38  [-2.85602757e-04 -2.60602799e-04 -2.54352693e-...  20000\n",
       "39  [-0.00018209 -0.00017896 -0.00023209 ...  0.00...  20000\n",
       "40  [-0.00010901 -0.00010276 -0.00011526 ... -0.00...  20000\n",
       "41  [ 2.64029950e-07 -8.41109431e-05 -6.22359803e-...  20000\n",
       "42  [-8.07247707e-05 -8.38498236e-05 -7.75997760e-...  20000\n",
       "43  [-0.00025545 -0.00028045 -0.00023358 ... -0.00...  20000\n",
       "44  [-2.10954575e-04 -1.14079623e-04 -9.84545914e-...  20000\n",
       "45  [-0.00027318 -0.00023256 -0.00030443 ... -0.00...  20000\n",
       "46  [-2.65048118e-04 -2.49423028e-04 -1.11923087e-...  20000\n",
       "47  [-2.35307554e-04 -1.88432517e-04 -2.29057507e-...  20000\n",
       "48  [-2.25204625e-04 -1.56454567e-04 -1.06454594e-...  20000\n",
       "49  [-0.00036108 -0.00028608 -0.00026108 ... -0.00...  20000\n",
       "50  [-0.00022867 -0.00029117 -0.00027242 ...  0.00...  20000\n",
       "51  [-0.00030486 -0.00030799 -0.00039861 ... -0.01...  20000\n",
       "52  [-0.00017855 -0.0002223  -0.00018792 ... -0.00...  20000\n",
       "53  [-3.10976116e-04 -3.32851196e-04 -3.32851138e-...  20000\n",
       "54  [-0.00017834 -0.00011896 -0.00016271 ...  0.00...  20000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract variables that contain related data\n",
    "vowel_np = np.load(\"Data/%s/voice_%s.npy\" % (subject, vowel))\n",
    "print(vowel_np)\n",
    "\n",
    "vowel_df = pd.read_csv(\"Data/%s/voice_%s.csv\" % (subject, vowel))\n",
    "vowel_df\n",
    "print(type(vowel_df.iloc[0,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowel_sample = np.fromstring(vowel_df['Signal'][0], dtype=float, sep='\\n')\n",
    "vowel_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features from Vowels\n",
    "Load the vowels and extrac MFCC features from each repetition to construct the training vectors to train the HMM model\n",
    "### Mel Frequency Cepstral Coefficient (MFCC) \n",
    "1. Frame the signal into short frames.\n",
    "2. For each frame calculate the periodogram estimate of the power spectrum.\n",
    "3. Apply the mel filterbank to the power spectra, sum the energy in each filter.\n",
    "4. Take the logarithm of all filterbank energies.\n",
    "5. Take the DCT of the log filterbank energies.\n",
    "6. Keep DCT coefficients 2-13, discard the rest.\n",
    "\n",
    "Example:\n",
    "<img src=\"Figure/time_signal.jpg\" width=\"700\"/>\n",
    "<img src=\"Figure/mfcc_raw.jpg\" width=\"700\"/>\n",
    "\n",
    "### Reference\n",
    "Davis, S. Mermelstein, P. (1980) Comparison of Parametric Representations for Monosyllabic Word Recognition in Continuously Spoken Sentences. In IEEE Transactions on Acoustics, Speech, and Signal Processing, Vol. 28 No. 4, pp. 357-366\n",
    "\n",
    "X. Huang, A. Acero, and H. Hon. Spoken Language Processing: A guide to theory, algorithm, and system development. Prentice Hall, 2001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-bdef49783773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# an overlapping analysis window of 25ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m mfcc_feat = mfcc(vowel_df['Signal'][0], vowel_df['Sampling Rate'][0], \n\u001b[0;32m----> 4\u001b[0;31m                  0.025, 0.001)\n\u001b[0m",
      "\u001b[0;32m~/tensorflow/venv/lib/python3.6/site-packages/python_speech_features/base.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(signal, samplerate, winlen, winstep, numcep, nfilt, nfft, lowfreq, highfreq, preemph, ceplifter, appendEnergy, winfunc)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNUMFRAMES\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnumcep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mEach\u001b[0m \u001b[0mrow\u001b[0m \u001b[0mholds\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfbank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwinlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwinstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfilt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhighfreq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreemph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwinfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ortho'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnumcep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/venv/lib/python3.6/site-packages/python_speech_features/base.py\u001b[0m in \u001b[0;36mfbank\u001b[0;34m(signal, samplerate, winlen, winstep, nfilt, nfft, lowfreq, highfreq, preemph, winfunc)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[1;32m     53\u001b[0m     \u001b[0mhighfreq\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mhighfreq\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreemphasis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreemph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframesig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinlen\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinstep\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwinfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mpspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpowspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/venv/lib/python3.6/site-packages/python_speech_features/sigproc.py\u001b[0m in \u001b[0;36mpreemphasis\u001b[0;34m(signal, coeff)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfiltered\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcoeff\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "# MFCC feature vectors are typically computed every 10ms using \n",
    "# an overlapping analysis window of 25ms\n",
    "mfcc_feat = mfcc(vowel_df['Signal'][0], vowel_df['Sampling Rate'][0], \n",
    "                 0.025, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatnate individual feature into one single array\n",
    "vowel_feature = np.append(vowel_feature, mfcc_feat, axis=0)\n",
    "length.append(int(mfcc_feat.shape[0]))\n",
    "\n",
    "print('Dimensionality of ONE vowel features: ', vowel_feature[0].shape)        \n",
    "print('Total # of feature sequence: ', vowel_feature.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: Load training vowels and extract features\n",
    "Load 50 repetitions from normal vowels production and then extract MFCC cofficients from each vowel to train the HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vowels_training(vowel):\n",
    "    Tmp_Data = vowel['data']\n",
    "    Start = vowel['datastart']\n",
    "    End = vowel['dataend']\n",
    "    Sample_Rate = vowel['samplerate']\n",
    "\n",
    "    rep = Start.shape[1]\n",
    "    sample_rate = Sample_Rate[4,0]\n",
    "\n",
    "    print('Total Repetitions:', rep)\n",
    "    print(\"Sampling Rate: \", sample_rate)\n",
    "\n",
    "    # Extract features from all 55 rep of voice signals\n",
    "    vowel_feature = np.empty((0, 13))\n",
    "    length = []\n",
    "    for i in range(50):\n",
    "        # Get the indices for the current repetiton\n",
    "        voice_start = int(Start[4,i]) - 1\n",
    "        voice_end = int(End[4,i])\n",
    "\n",
    "        # Extract and center the current voice signal\n",
    "        voice_sample = Tmp_Data[0,voice_start:voice_end]\n",
    "        voice_sample = voice_sample - np.mean(voice_sample)\n",
    "\n",
    "        # MFCC feature vectors are typically computed every 10ms using \n",
    "        # an overlapping analysis window of 25ms\n",
    "        mfcc_feat = mfcc(voice_sample, sample_rate, 0.001*win_overlap, 0.001*win_step)\n",
    "\n",
    "        # Concatnate individual feature into one single array\n",
    "        vowel_feature = np.append(vowel_feature, mfcc_feat, axis=0)\n",
    "        length.append(int(mfcc_feat.shape[0]))\n",
    "\n",
    "    print('Dimensionality of ONE vowel features: ', vowel_feature[0].shape)        \n",
    "    print('Total # of feature sequence: ', vowel_feature.shape[0])\n",
    "\n",
    "    return vowel_feature, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_a_tr, length_a_tr = load_vowels_training(vowel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training a HMM Model\n",
    "Use Gaussian distribution for estimating emission probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize HMM model and estimate parameters for /a/ normal\n",
    "transmat = np.zeros((num_components, num_components))\n",
    "\n",
    "# Left-to-right: each state is connected to itself and its\n",
    "# direct successor.\n",
    "for i in range(num_components):\n",
    "    if i == num_components - 1:\n",
    "        transmat[i, i] = 1.0\n",
    "    else:\n",
    "        transmat[i, i] = transmat[i, i + 1] = 0.5\n",
    "\n",
    "        \n",
    "print(transmat)\n",
    "\n",
    "# Always start in first state\n",
    "startprob = np.zeros(num_components)\n",
    "startprob[0] = 1.0\n",
    "\n",
    "model_vowel = hmm.GaussianHMM(n_components=num_components,  \n",
    "                              covariance_type=\"full\",\n",
    "                              params=\"mct\", \n",
    "                              init_params=\"cm\",\n",
    "                              n_iter=100)\n",
    "\n",
    "model_vowel.startprob = startprob.copy()\n",
    "model_vowel.transmat_ = transmat.copy()\n",
    "\n",
    "model_vowel.fit(feature_a_tr, length_a_tr)\n",
    "model_vowel.monitor_\n",
    "\n",
    "print(model_vowel.transmat_)\n",
    "print(model_vowel.means_.shape)\n",
    "print(model_vowel.covars_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model_vowel.means_)\n",
    "print(model_vowel.covars_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do: \n",
    "Re-order the state sequence based on the variance of that particular state. The intuition here is assuming that the empty (quiet) state 0 has the smallest variance; the beginning state 1 of a vowel has the medium amount of variance; and the main vowel state 2 should have the largest variance.\n",
    "### !!!!!Note to myself!!!!!\n",
    "Inside GaussianHMM class, \\_init function, there is a step uses kmean to cluster given observations for the initial estimation of means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use Trainned HMM Model to Perform State Prediction on Given Voices\n",
    "Use the three HMM models which are estimated previously for /a/ normal, /u/ normal, /i/ normal to:\n",
    "1. Find corresponding states on original vowel signals for reference.\n",
    "2. Predict corresponding states for given syllables to validate the models.\n",
    "3. Predict corresponding states for given sentences to test the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Use vowels as tesing voice signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: Load testing voice (vowels or speeches), extract features\n",
    "Similar to the function of loading training vowels. However, this only loads one repetition for qualitative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_voice_testing(voice, index, L):\n",
    "    Tmp_Data = voice['data']\n",
    "    Start = voice['datastart']\n",
    "    End = voice['dataend']\n",
    "    Sample_Rate = voice['samplerate']\n",
    "\n",
    "    rep = Start.shape[1]\n",
    "    sample_rate = Sample_Rate[4,0]\n",
    "\n",
    "    # Extract features from all 55 rep of voice signals\n",
    "    voice_feature = np.empty((0, 13))\n",
    "    length = []\n",
    "\n",
    "    # Get the indices for the current repetiton\n",
    "    voice_start = int(Start[4,index]) - 1\n",
    "    voice_end = int(End[4,index])\n",
    "\n",
    "    # Extract and center the current voice signal\n",
    "    voice_sample = Tmp_Data[0,voice_start:voice_end]\n",
    "    voice_sample = voice_sample - np.mean(voice_sample)\n",
    "\n",
    "    # MFCC feature vectors are typically computed every 10ms using \n",
    "    # an overlapping analysis window of 25ms\n",
    "    mfcc_feat = mfcc(voice_sample, sample_rate, 0.001*win_overlap, 0.001*win_step)\n",
    "\n",
    "    # Concatnate individual feature into one single array\n",
    "    voice_feature = np.append(voice_feature, mfcc_feat, axis=0)\n",
    "    length.append(int(mfcc_feat.shape[0]))\n",
    "\n",
    "    # Plot ONE voice sample signals    \n",
    "    plt.figure(1, figsize=(15, 6))\n",
    "    plt.plot(voice_sample)\n",
    "#     plt.ylim(-0.04, 0.04)\n",
    "    plt.xlim(L[0], L[1])\n",
    "    plt.title(\"Testing Voice\")\n",
    "    plt.show()\n",
    "    \n",
    "    return voice_sample, voice_feature, length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load testing vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_te, feature_te, length_te = load_voice_testing(vowel_data, 54, [0, 40000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Function: Restore states prediction from the feature space to the original signal space\n",
    "The voice feature vectors are extracted every 10ms using a 25ms overlapping window. Thus, each predicted state for the feature vector need to be expanded to the original voice signal in order to get the indices for the start and end for the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_vec = ['r','g','y','c','m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_voice_state(model, voice_sample, voice_feature, c, L):\n",
    "    \"\"\" THIS PARAMETER NEED TO BE FURTHER INVESTIGATED \"\"\"\n",
    "    # sample window = time x sampling rate\n",
    "    sample_window = int(0.01 * 20000)\n",
    "    \"\"\" THIS PARAMETER NEED TO BE FURTHER INVESTIGATED \"\"\"\n",
    "\n",
    "    # Use trainned HMM to predict the states\n",
    "    state_prediction = model.predict(voice_feature)\n",
    "    state_length = len(state_prediction)\n",
    "\n",
    "#     print(state_prediction)\n",
    "\n",
    "    # Expand the state prediction from feature vectors to the original\n",
    "    # voice signals\n",
    "    # i - index\n",
    "    # s - state\n",
    "    voice_state = np.zeros((num_components,voice_sample.size))\n",
    "    for i,s in enumerate(state_prediction):\n",
    "\n",
    "        # Skip the first and last state to make it able to detect \n",
    "        # after differentiation\n",
    "        # the first state\n",
    "        if i == 0:\n",
    "            for j in range(1, sample_window):\n",
    "                voice_state[s,j] = 1\n",
    "        # from the second state until the second last state\n",
    "        elif i < state_length - 1:\n",
    "            for j in range(i*sample_window, i*sample_window+sample_window):\n",
    "                voice_state[s,j] = 1\n",
    "        # last state\n",
    "        else:\n",
    "            for j in range(i*sample_window, voice_sample.size-1):\n",
    "                voice_state[s,j] = 1\n",
    "\n",
    "    # Plot the expanded voice state sequence\n",
    "    plt.figure(2, figsize=(15, 6))\n",
    "    plt.plot(voice_sample, c='b', alpha=0.8)\n",
    "#     c = ['r','g','y']\n",
    "\n",
    "    for s in range(0,num_components):\n",
    "        i_start = []    # all start indices for the current state\n",
    "        i_end   = []    # all end indices for the current state\n",
    "\n",
    "        # peform the differentiation\n",
    "        voice_detect = np.diff(voice_state[s,:])\n",
    "        # find non-zero elements +1/-1\n",
    "        for i, v in enumerate(voice_detect):\n",
    "            if v == 1:\n",
    "                i_start.append(i)\n",
    "            elif v == -1:\n",
    "                i_end.append(i)\n",
    "\n",
    "        for i,j in zip(i_start, i_end):\n",
    "            p = plt.axvspan(i, j, facecolor=c[s] , alpha=0.4)\n",
    "\n",
    "    plt.xlim(L[0], L[1])    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict testing vowels\n",
    "State sequence order: red   ---> 0, green ---> 1, yello ---> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_voice_state(model_vowel, voice_te, feature_te, color_vec, [0, 40000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Using syllable1 as tesing voice signal\n",
    "\n",
    "“afa afa afa ifi ifi ifi ufu ufu ufu”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable = sio.loadmat('Data/%s/syllable1.mat' % subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_syl_te, feature_syl_te, length_syl_te = load_voice_testing(syllable, 0, [0,120000])\n",
    "predict_voice_state(model_vowel, voice_syl_te, feature_syl_te, color_vec, [0,120000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zoom in the first part of this syllable sequence to better evaluate \"afa afa afa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_syl_te, feature_syl_te, length_syl_te = load_voice_testing(syllable, 0, [0,30000])\n",
    "predict_voice_state(model_vowel, voice_syl_te, feature_syl_te, color_vec, [0,30000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Using sentence as tesing voice signal\n",
    "<img src=\"Figure/sentence_ref.png\" width=\"500\"/>\n",
    "\n",
    "### Reference\n",
    "Y.-A. Lien, C. Gattuccio, and C. Stepp, “Effects of phonetic context on relative fundamental frequency,” Journal of Speech, Language, and Hearing Research, vol. 57, pp. 1259–1267, 2014.\n",
    "\n",
    "Elizabeth S.Heller Murray, Gabrielle L. Hands, Carolyn R. Calabrese, Cara E. Stepp, Effects of Adventitious Acute Vocal Trauma: Relative Fundamental Frequency and Listener Perception, Journal of Voice, Volume 30, Issue 2, 2016, Pages 177-185."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentence 1 \n",
    "“The d**ew shi**mmered over m**y shi**ny blue shell again”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = sio.loadmat('Data/%s/sentence1.mat' % subject)\n",
    "voice_stn_te, feature_stn_te, length_stn_te = load_voice_testing(sentence1, 0, [0, 60000])\n",
    "predict_voice_state(model_vowel, voice_stn_te, feature_stn_te, color_vec,[0, 60000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentence 2\n",
    "“Only w**e fee**l you d**o fai**l in n**ew fa**llen dew”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2 = sio.loadmat('Data/%s/sentence2.mat' % subject)\n",
    "voice_stn_te, feature_stn_te, length_stn_te = load_voice_testing(sentence2, 0, [0, 60000])\n",
    "predict_voice_state(model_vowel, voice_stn_te, feature_stn_te, color_vec,[0, 60000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
